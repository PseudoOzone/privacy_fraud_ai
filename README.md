# ğŸ¦ Privacy-Fraud-AI â€” Federated + Gen-AI Fraud Detection Suite

This repository contains a research-grade project that demonstrates:

| Module | Description |
|--------|-------------|
| ğŸ” Federated ML | Train fraud-detection models across banks without sharing raw data |
| ğŸ” Differential Privacy | Wrap models so shared output cannot leak sensitive information |
| ğŸ¤– Gen-AI Fraud Agent | LLM that reads aggregated stats â†’ outputs fraud summaries and synthetic attack patterns |
| ğŸ§ª Synthetic Data Generator | Automates new fraud-like events to expand model training |

---

## ğŸ¯ Goal of the Project

Real-world banks cannot share user data (PII).  
This project showcases a **privacy-preserving fraud intelligence system** that works **without exposing names, emails, phone numbers or accounts.**

It includes:

| Feature | Status |
|--------|--------|
| Federated Learning across institutions | âœ… |
| DP-safe prediction wrapper | âœ… |
| Synthetic Fraud Pattern Generator (Gen-AI) | âœ… |
| Aggregated-only LLM summaries | ğŸš§ improving |
| Real-time anomaly scoring | ğŸ”œ upcoming |
| Dashboard & API endpoint | ğŸ”œ upcoming |

---

## ğŸ—ï¸ Architecture

```
Bank A CSV â”€â”€â”       â”Œâ”€ Aggregated statistics â”€â”€â–º Gen-AI Summary
              â”‚       â”‚
              â–¼       â–¼
Local RandomForest  Local RandomForest
       â”‚                   â”‚
       â””â”€â”€â”€â”€ Fed-Merge â†’ Global Model (No raw data shared)
                â”‚
                â”œâ”€â”€ DP Wrapper â€“ noise added
                â”‚
                â”œâ”€â”€ Save â†’ models/global_model_dp.pkl
                â”‚
                â””â”€â”€ Predict on new CSV safely
```

---

## ğŸ“Œ How to Use

### 1ï¸âƒ£ Run in Google Colab
```bash
git clone https://github.com/<yourname>/privacy_fraud_ai.git
cd privacy_fraud_ai
```
Open `notebooks/federated_training.ipynb` â†’ Run all  
Outputs:
- `models/global_model.pkl`
- `models/global_model_dp.pkl`

### 2ï¸âƒ£ Generate Synthetic Fraud Records (LLM-based)
```python
!python src/gen_fraud_ai.py
```
Outputs:
```
/results/synthetic_outputs.csv
```

---

## ğŸ” Differential Privacy

Instead of modifying internal RandomForest weights (unsafe),  
we apply **output-side noise**:

```python
pred = real_pred + Normal(0, sigma)
pred = clip(pred,0,1)
```

This ensures:
- bank-to-bank model sharing is safe
- attacker cannot infer original customer values

---

## ğŸ“Š Example Synthetic Patterns

```
1) POS: 12 transactions in 24 seconds
2) Mobile: 7 failed attempts then 2 success
3) ATM: 8 withdrawals escalating from 83 to 313
4) Web: 14 retries until 5 approval
```

---

## ğŸ§ª Dataset Disclaimer

All CSVs in `/data` are either:
âœ” fake  
âœ” synthetic  
âœ” or anonymized for research  

No real PII exists.

---

## ğŸ§  Research Extensions You Can Add

| Idea | Type |
|------|------|
| Adaptive meta-learning fraud model | Research publication |
| New-device fingerprint signal embedding | Patent-potential |
| Real-time feature drift detection | Enterprise deployment |
| Blockchain-signed federated updates | Security research |

---

## ğŸ“œ License
MIT License â€” free to use for academic + portfolio work.

---

## ğŸ§‘â€ğŸ’¼ Author
Built by **Anshuman Bakshi** â€” AI researcher ğŸŒ™
